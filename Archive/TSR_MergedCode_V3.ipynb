{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TODO List\\nLogic: \\n1. Write output to xlsx instead of CSV \\n2. Display the path of the final output file in a messagebox or a label? \\n3. Error handling\\n    - Incorrect file selection (based on column names) - add elif to exception\\n    - file containing special characters that algorithm cannot process\\n4. Remove Index column before saving\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''TODO List\n",
    "Logic: \n",
    "1. Write output to xlsx instead of CSV \n",
    "2. Display the path of the final output file in a messagebox or a label? \n",
    "3. Error handling\n",
    "    - Incorrect file selection (based on column names) - add elif to exception\n",
    "    - file containing special characters that algorithm cannot process\n",
    "4. Remove Index column before saving\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.14 |Anaconda, Inc.| (default, Nov  8 2017, 13:40:45) [MSC v.1500 64 bit (AMD64)]\n",
      "C:\\ProgramData\\Anaconda2\\python.exe\n",
      "<module 'sys' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(sys.executable)\n",
    "print (sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MENU \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import en\n",
    "\n",
    "#Tkinter libraries\n",
    "from Tkinter import *\n",
    "from Tkinter import Menu\n",
    "import tkFileDialog\n",
    "import Tkconstants\n",
    "import tkMessageBox\n",
    "\n",
    "#Training libraries\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "#converting String to Pandas df\n",
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "    \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training algorigthm\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple 'should'\n",
    "def transform_stmt_mul_shd(stmt):\n",
    "    temp_pst_collate = \"\"\n",
    "    splt_sentence = stmt.split(\"and\")\n",
    "    for stmt in splt_sentence:\n",
    "        temp_pst_collate = temp_pst_collate + 'and' + transform_stmt_single_shd(stmt)\n",
    "        #print(temp_pst_collate)\n",
    "    return temp_pst_collate[3:]          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single 'should'\n",
    "def transform_stmt_single_shd(stmt): \n",
    "    words = nltk.word_tokenize(stmt)\n",
    "    veb_lst = [word for (word, pos) in nltk.pos_tag(words) if is_verb(pos)]\n",
    "    \n",
    "    if (stmt.find(\"should not\") > -1) and ('be' in veb_lst):\n",
    "        trnf_pst_stmt = stmt.replace(\"should not be\", \"is not\")\n",
    "        return trnf_pst_stmt\n",
    "    \n",
    "    elif (stmt.find(\"should\") > -1) and ('be' in veb_lst) and (stmt.find(\"details\") > -1):\n",
    "        trnf_pst_stmt = stmt.replace(\"should be\", \"are\")\n",
    "        return trnf_pst_stmt\n",
    "    \n",
    "    elif (stmt.find(\"should\") > -1) and ('be' in veb_lst) and (stmt.find(\"properties\") > -1):\n",
    "        trnf_pst_stmt = stmt.replace(\"should be\", \"are\")\n",
    "        return trnf_pst_stmt\n",
    "    \n",
    "    elif (stmt.find(\"should\") > -1) and ('be' in veb_lst) and (stmt.find(\"fields\") > -1):\n",
    "        trnf_pst_stmt = stmt.replace(\"should be\", \"are\")\n",
    "        return trnf_pst_stmt\n",
    "    \n",
    "    elif (stmt.find(\"should\") > -1) and ('be' in veb_lst) and (stmt.find(\"sections\") > -1):\n",
    "        trnf_pst_stmt = stmt.replace(\"should be\", \"are\")\n",
    "        return trnf_pst_stmt\n",
    "         \n",
    "    elif (stmt.find(\"should\") > -1) and ('be' in veb_lst):\n",
    "        trnf_pst_stmt = stmt.replace(\"should be\", \"is\")\n",
    "        return trnf_pst_stmt\n",
    "        \n",
    "    elif (stmt.find(\"should\") > -1) and ('be' not in veb_lst):\n",
    "        trnf_pst_stmt = stmt.replace(\"should \"+veb_lst[0], en.verb.present(veb_lst[0].lower()))\n",
    "        return trnf_pst_stmt\n",
    "    \n",
    "    else:\n",
    "        return stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function that will retrive only base verb forms\n",
    "is_verb = lambda pos: pos == 'VB' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process Expected result - convert to past tense\n",
    "def processExpRes(df):\n",
    "    #verb_lst = []\n",
    "    all_past_stmt = []\n",
    "    temp_pst = \"\"\n",
    "\n",
    "    for test_case in list(df[\"Expect_res\"]):\n",
    "        stmt_lst = custom_sent_tokenizer.tokenize(test_case)\n",
    "        try:\n",
    "            for stmt in stmt_lst:\n",
    "                words = nltk.word_tokenize(stmt)\n",
    "                if words.count(\"should\") > 1:\n",
    "                    temp_pst = temp_pst + '\\n' + transform_stmt_mul_shd(stmt)\n",
    "                else:\n",
    "                    temp_pst = temp_pst + '\\n' + transform_stmt_single_shd(stmt)\n",
    "                \n",
    "            all_past_stmt.append(temp_pst[1:])\n",
    "            #print (temp_pst)\n",
    "            temp_pst = \"\"\n",
    "\n",
    "        except Exception as e:\n",
    "            all_past_stmt.append(test_case)\n",
    "            print(str(e))\n",
    "    se = pd.Series(all_past_stmt)\n",
    "    df['Converted_Expected'] = se.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process actual result - trim User Info\n",
    "def processActRes(df):\n",
    "    trm_act_res = []\n",
    "    for test_case in list(df[\"actualresult\"]):\n",
    "        try:\n",
    "            #print (test_case)\n",
    "            trm_act_res.append(test_case[:test_case.rfind(\"[\")])\n",
    "        except Exception as e:\n",
    "            trm_act_res.append(test_case)\n",
    "            print(str(e))   \n",
    "    ac = pd.Series(trm_act_res)\n",
    "    df['Converted_Actual'] = ac.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatecompResult(df):\n",
    "    cmpexpactlst = []\n",
    "    resulttxt = ''\n",
    "    for index, row in df.iterrows():\n",
    "        #print(row[\"Converted_Expected\"] +\"----> \\n\"+  row[\"Converted_Actual\"])\n",
    "\n",
    "        x = row[\"Converted_Expected\"].replace(' ', '')\n",
    "        x1 = x.replace('\\n', '') #replacing new lines\n",
    "        x2 = x1.replace('\\r', '')#replacing returns\n",
    "\n",
    "        y = row[\"Converted_Actual\"].replace(' ', '')\n",
    "        y1 = y.replace('\\n', '') #replacing new lines\n",
    "        y2 = y1.replace('\\r', '') #replacing returnss\n",
    "\n",
    "        if x2 == y2:\n",
    "            resulttxt = 'Approved'\n",
    "        elif x2 in y2:\n",
    "            #y2.contains(x2):\n",
    "            resulttxt = 'Approved'\n",
    "        else:\n",
    "            resulttxt = 'Verify'\n",
    "        cmpexpactlst.append(resulttxt)\n",
    "    res = pd.Series(cmpexpactlst)\n",
    "    df[\"Compare_result\"] = res.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "(1382, 5)\n",
      "(1382, 6)\n",
      "(1382, 7)\n",
      "2018_04_27_225018\n",
      "I got 345352 bytes from this file.\n",
      "No module named GeneratingSummary\n"
     ]
    }
   ],
   "source": [
    "#main fn\n",
    "root = Tk()\n",
    "root.title(\"test\")\n",
    "\n",
    "root.geometry('500x500')\n",
    "\n",
    "def hello():\n",
    "      print \"hello!\"\n",
    "\n",
    "def close_window(): \n",
    "    root.destroy()\n",
    "\n",
    "def generatefile():\n",
    "    try:\n",
    "        file = tkFileDialog.askopenfile(parent=root,mode='rb',title='Choose a file')\n",
    "        if file != None:\n",
    "            data = file.read()\n",
    "\n",
    "            #convert file data from String to df\n",
    "            TESTDATA = StringIO(data)\n",
    "            df = pd.read_csv(TESTDATA, sep=\",\")\n",
    "\n",
    "            #calling the process convert expected result function here\n",
    "            processExpRes(df)\n",
    "            print (df.shape)\n",
    "\n",
    "            #calling the process convert act result fucntion here\n",
    "            processActRes(df)\n",
    "            print (df.shape)\n",
    "\n",
    "            #calling generate comparison function here\n",
    "            generatecompResult(df)\n",
    "            print (df.shape)\n",
    "\n",
    "            time = datetime.datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "            print (time)\n",
    "\n",
    "            df.to_csv('C:\\\\Users\\\\A6LBGZZ\\\\Desktop\\\\./FinalOutput_{}.csv'.format(time), encoding='utf-8')\n",
    "            #df.to_excel('./FinalOutput_{}.xlsx'.format(time), encoding='utf-8')\n",
    "            tkMessageBox.showinfo(\"Title\", \"HANU\")\n",
    "\n",
    "            file.close()\n",
    "            print \"I got %d bytes from this file.\" % len(data)\n",
    "            \n",
    "            from GeneratingSummary import hello\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        if e ==\"'ascii' codec can't decode byte 0xe2 in position 163: ordinal not in range(128)\":\n",
    "            tkMessageBox.showinfo(\"Error\", \"Cannot write to xls\")\n",
    "\n",
    "menu = Menu(root)\n",
    "new_item = Menu(menu)\n",
    "\n",
    "filemenu = Menu(menu, tearoff=0)\n",
    "filemenu.add_command(label=\"Open\", command=hello)\n",
    "filemenu.add_command(label=\"Save\", command=hello)\n",
    "filemenu.add_separator()\n",
    "filemenu.add_command(label=\"Exit\", command=root.destroy)\n",
    "menu.add_cascade(label=\"File\", menu=filemenu)\n",
    "\n",
    "brwsLbl1=Label(root)\n",
    "brwsLbl1.grid(row=3, column=2)\n",
    "\n",
    "#brwsBtn=Button(root, text=\"Browse\", command=generatefile)\n",
    "#brwsBtn.grid(row=2, column=1)\n",
    "\n",
    "brwsLbl=Label(root)\n",
    "brwsLbl.grid(row=3, column=2)\n",
    "\n",
    "prcsBtn=Button(root, text=\"BROWSE & PROCESS\", command=generatefile)\n",
    "prcsBtn.grid(row=5, column=5)\n",
    "\n",
    "exitBtn = Button(root, text = \"EXIT\", command = close_window)\n",
    "exitBtn.grid(row=8, column=8)\n",
    "\n",
    "#table = tktable.Table(root, rows=10, cols=4)\n",
    "#table.pack(side=\"top\", fill=\"both\", expand=True)\n",
    "\n",
    "root.config(menu=menu)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
