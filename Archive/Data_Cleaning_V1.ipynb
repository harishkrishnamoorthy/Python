{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import en\n",
    "#import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sams.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the algorithm\n",
    "#To-do: Instead of speech train it on actual test case corpus\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fn: Rule engine for multiple 'should' statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_stmt_mul_shd(stmt):\n",
    "    temp_pst_collate = \"\"\n",
    "    splt_sentence = stmt.split(\"and\")\n",
    "    for stmt in splt_sentence:\n",
    "        temp_pst_collate = temp_pst_collate + 'and' + transform_stmt_single_shd(stmt)\n",
    "    return temp_pst_collate[4:]          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fn: Rule engine for single 'should' statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_stmt_single_shd(stmt): \n",
    "    words = nltk.word_tokenize(stmt)\n",
    "    veb_lst = [word for (word, pos) in nltk.pos_tag(words) if is_verb(pos)]\n",
    "    \n",
    "    if (stmt.find(\"should not\") > -1) and ('be' in veb_lst):\n",
    "        trnf_pst_stmt = stmt.replace(\"should not be\", \"were not\")\n",
    "        return trnf_pst_stmt\n",
    "    \n",
    "    elif (stmt.find(\"should\") > -1) and ('be' in veb_lst) and (stmt.find(\"fields\") > -1):\n",
    "        trnf_pst_stmt = stmt.replace(\"should be\", \"were\")\n",
    "        return trnf_pst_stmt\n",
    "    \n",
    "    elif (stmt.find(\"should\") > -1) and ('be' in veb_lst):\n",
    "        trnf_pst_stmt = stmt.replace(\"should be\", \"was\")\n",
    "        return trnf_pst_stmt\n",
    "    \n",
    "    elif (stmt.find(\"should\") > -1) and ('be' not in veb_lst):\n",
    "        trnf_pst_stmt = stmt.replace(\"should \"+veb_lst[0], en.verb.past(veb_lst[0].lower()))\n",
    "        return trnf_pst_stmt\n",
    "    \n",
    "    else:\n",
    "        return stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function that will retrive only base verb forms\n",
    "is_verb = lambda pos: pos == 'VB' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verb_lst = []\n",
    "all_past_stmt = []\n",
    "temp_pst = \"\"\n",
    "\n",
    "for test_case in list(df[\"Expect_res\"]):\n",
    "    stmt_lst = custom_sent_tokenizer.tokenize(test_case)\n",
    "    try:\n",
    "        for stmt in stmt_lst:\n",
    "            words = nltk.word_tokenize(stmt)\n",
    "            if words.count(\"should\") > 1:\n",
    "                temp_pst = temp_pst + '\\n' + transform_stmt_mul_shd(stmt)\n",
    "            else:\n",
    "                temp_pst = temp_pst + '\\n' + transform_stmt_single_shd(stmt)\n",
    "                \n",
    "        all_past_stmt.append(temp_pst[1:])\n",
    "        temp_pst = \"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        all_past_stmt.append(test_case)\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding column to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = pd.Series(all_past_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['out'] = se.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(942, 4)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns the dimesnsion of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns number of lines in the list\n",
    "len(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(942, 4)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display dimension of the df after adding out column\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('FinalOut_1.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
