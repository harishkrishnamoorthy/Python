{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TODO List\\nLogic: \\n1. Display the path of the final output file in a messagebox or a label? \\n2. Error handling\\n    - Incorrect file selection (based on column names) - add elif to exception\\n    - file containing special characters that algorithm cannot process\\n3. Filepath and save path display on screen\\n4. Read from excel in pandas\\n5. Generating executable \\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''TODO List\n",
    "Logic: \n",
    "1. Display the path of the final output file in a messagebox or a label? \n",
    "2. Error handling\n",
    "    - Incorrect file selection (based on column names) - add elif to exception\n",
    "    - file containing special characters that algorithm cannot process\n",
    "3. Filepath and save path display on screen\n",
    "4. Read from excel in pandas\n",
    "5. Generating executable\n",
    "6. Text Wrap in output\n",
    "7. Column sizing / borders / font\n",
    "8. Remove converted actual from the final output file - done\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.14 |Anaconda, Inc.| (default, Nov  8 2017, 13:40:45) [MSC v.1500 64 bit (AMD64)]\n",
      "C:\\ProgramData\\Anaconda2\\python.exe\n",
      "<module 'sys' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(sys.executable)\n",
    "print (sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ascii\n"
     ]
    }
   ],
   "source": [
    "print (sys.getdefaultencoding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload(sys)  \n",
    "#sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MENU \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import en\n",
    "\n",
    "#Tkinter libraries\n",
    "from Tkinter import *\n",
    "from Tkinter import Menu\n",
    "import tkFileDialog\n",
    "import Tkconstants\n",
    "import tkMessageBox\n",
    "\n",
    "#Training libraries\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "#converting String to Pandas df\n",
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "    \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training algorigthm\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple 'should'\n",
    "def transform_stmt_mul_shd(stmt):\n",
    "    temp_pst_collate = \"\"\n",
    "    splt_sentence = stmt.split(\"and\")\n",
    "    for stmt in splt_sentence:\n",
    "        temp_pst_collate = temp_pst_collate + 'and' + transform_stmt_single_shd(stmt)\n",
    "        #print(temp_pst_collate)\n",
    "    return temp_pst_collate[3:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single 'should'\n",
    "def transform_stmt_single_shd(stmt): \n",
    "    words = nltk.word_tokenize(stmt)\n",
    "    veb_lst = [word for (word, pos) in nltk.pos_tag(words) if is_verb(pos)]\n",
    "    \n",
    "    if (stmt.find(\"should not\") > -1) and ('be' in veb_lst):\n",
    "        trnf_pst_stmt = stmt.replace(\"should not be\", \"is not\")\n",
    "        return trnf_pst_stmt\n",
    "    \n",
    "    elif (stmt.find(\"should\") > -1) and ('be' in veb_lst) and (stmt.find(\"details\") > -1):\n",
    "        trnf_pst_stmt = stmt.replace(\"should be\", \"are\")\n",
    "        return trnf_pst_stmt\n",
    "    \n",
    "    elif (stmt.find(\"should\") > -1) and ('be' in veb_lst) and (stmt.find(\"properties\") > -1):\n",
    "        trnf_pst_stmt = stmt.replace(\"should be\", \"are\")\n",
    "        return trnf_pst_stmt\n",
    "    \n",
    "    elif (stmt.find(\"should\") > -1) and ('be' in veb_lst) and (stmt.find(\"fields\") > -1):\n",
    "        trnf_pst_stmt = stmt.replace(\"should be\", \"are\")\n",
    "        return trnf_pst_stmt\n",
    "    \n",
    "    elif (stmt.find(\"should\") > -1) and ('be' in veb_lst) and (stmt.find(\"sections\") > -1):\n",
    "        trnf_pst_stmt = stmt.replace(\"should be\", \"are\")\n",
    "        return trnf_pst_stmt\n",
    "         \n",
    "    elif (stmt.find(\"should\") > -1) and ('be' in veb_lst):\n",
    "        trnf_pst_stmt = stmt.replace(\"should be\", \"is\")\n",
    "        return trnf_pst_stmt\n",
    "        \n",
    "    elif (stmt.find(\"should\") > -1) and ('be' not in veb_lst):\n",
    "        trnf_pst_stmt = stmt.replace(\"should \"+veb_lst[0], en.verb.past(veb_lst[0].lower()))\n",
    "        return trnf_pst_stmt\n",
    "    \n",
    "    else:\n",
    "        return stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function that will retrive only base verb forms\n",
    "is_verb = lambda pos: pos == 'VB' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process Expected result - convert to past tense\n",
    "def processExpRes(df):\n",
    "    #verb_lst = []\n",
    "    all_past_stmt = []\n",
    "    temp_pst = \"\"\n",
    "\n",
    "    for test_case in list(df[\"test_Step_Expected_result\"]):\n",
    "        stmt_lst = custom_sent_tokenizer.tokenize(test_case)\n",
    "        try:\n",
    "            for stmt in stmt_lst:\n",
    "                words = nltk.word_tokenize(stmt)\n",
    "                if words.count(\"should\") > 1:\n",
    "                    temp_pst = temp_pst + '\\n' + transform_stmt_mul_shd(stmt)\n",
    "                else:\n",
    "                    temp_pst = temp_pst + '\\n' + transform_stmt_single_shd(stmt)\n",
    "                \n",
    "            all_past_stmt.append(temp_pst[1:])\n",
    "            #print (temp_pst)\n",
    "            temp_pst = \"\"\n",
    "\n",
    "        except Exception as e:\n",
    "            all_past_stmt.append(test_case)\n",
    "            print(str(e))\n",
    "    se = pd.Series(all_past_stmt)\n",
    "    df['Converted_Expected'] = se.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process actual result - trim User Info\n",
    "def processActRes(df):\n",
    "    trm_act_res = []\n",
    "    for test_case in list(df[\"test_step_Actual_result\"]):\n",
    "        try:\n",
    "            #print (test_case)\n",
    "            trm_act_res.append(test_case[:test_case.rfind(\"[\")])\n",
    "        except Exception as e:\n",
    "            trm_act_res.append(test_case)\n",
    "            print(str(e))   \n",
    "    ac = pd.Series(trm_act_res)\n",
    "    df['Converted_Actual'] = ac.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatecompResult(df):\n",
    "    cmpexpactlst = []\n",
    "    resulttxt = ''\n",
    "    for index, row in df.iterrows():\n",
    "        #print(row[\"Converted_Expected\"] +\"----> \\n\"+  row[\"Converted_Actual\"])\n",
    "\n",
    "        x = row[\"Converted_Expected\"].replace(' ', '')\n",
    "        x1 = x.replace('\\n', '') #replacing new lines\n",
    "        x2 = x1.replace('\\r', '')#replacing returns\n",
    "\n",
    "        y = row[\"Converted_Actual\"].replace(' ', '')\n",
    "        y1 = y.replace('\\n', '') #replacing new lines\n",
    "        y2 = y1.replace('\\r', '') #replacing returnss\n",
    "\n",
    "        if x2 == y2:\n",
    "            resulttxt = 'Approved'\n",
    "        elif x2 in y2:\n",
    "            #y2.contains(x2):\n",
    "            resulttxt = 'Approved'\n",
    "        else:\n",
    "            resulttxt = 'Verify'\n",
    "        cmpexpactlst.append(resulttxt)\n",
    "    res = pd.Series(cmpexpactlst)\n",
    "    df[\"Compare_result\"] = res.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateStepList(df):\n",
    "    keys,vals = df.sort_values('TEST_ID').values.T\n",
    "    ukeys, index = np.unique(keys, True)\n",
    "    arrays = np.split(vals, index[1:])\n",
    "    df2 = pd.DataFrame({'TEST_ID':ukeys, 'Steps to Verify':[list(a) for a in arrays]})\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSummary(df):\n",
    "    cnts = pd.DataFrame(df.TEST_ID.value_counts().reset_index())\n",
    "    cnts.columns = [\"TEST_ID\", \"Total Steps\"]\n",
    "    df1 = df.loc[df['Compare_result'] == \"Approved\"]\n",
    "    appcnts = pd.DataFrame(df1.TEST_ID.value_counts().reset_index())\n",
    "    appcnts.columns = [\"TEST_ID\", \"Approved\"]\n",
    "    df2 = df.loc[df['Compare_result'] == \"Verify\"]\n",
    "    vrfycnts = pd.DataFrame(df2.TEST_ID.value_counts().reset_index())\n",
    "    vrfycnts.columns = [\"TEST_ID\", \"Verify\"]\n",
    "    xxx = generateStepList(df2[['TEST_ID','test_step_name']])\n",
    "    df10 = cnts.merge(appcnts, on='TEST_ID', how='left').merge(vrfycnts, on='TEST_ID', how='left').merge(xxx, on='TEST_ID', how='left')\n",
    "    df11 = df10.fillna(0)\n",
    "    df11[['Approved','Verify']] = df11[['Approved','Verify']].astype(int)\n",
    "    df11['Action'] = df11.apply(lambda x: 'Approve' if x[\"Verify\"]==0 else 'Verify', axis=1)\n",
    "    final_sum_df = df11[[\"TEST_ID\", \"Action\", \"Total Steps\", \"Approved\", \"Verify\", \"Steps to Verify\"]]\n",
    "    return final_sum_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close Main window\n",
    "def close_window(): \n",
    "    root.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "(1381, 5)\n",
      "(1381, 6)\n",
      "(1381, 7)\n"
     ]
    }
   ],
   "source": [
    "#main fn\n",
    "root = Tk()\n",
    "root.title(\"TEST RESULTS REVIEW\")\n",
    "\n",
    "#window size\n",
    "root.geometry('250x250')\n",
    "\n",
    "#window resizable = False\n",
    "root.resizable(False, False)\n",
    "\n",
    "def hello():\n",
    "      print \"hello!\"\n",
    "\n",
    "def generatefile():\n",
    "    try:\n",
    "        file = tkFileDialog.askopenfile(parent=root,mode='rb', title='Choose a file')\n",
    "        if file != None:\n",
    "            data = file.read()\n",
    "\n",
    "            #convert file data from String to df\n",
    "            TESTDATA = StringIO(data)\n",
    "            df = pd.read_csv(TESTDATA, sep=\",\")\n",
    "\n",
    "            #calling the process convert expected result function here\n",
    "            processExpRes(df)\n",
    "            print (df.shape)\n",
    "\n",
    "            #calling the process convert act result fucntion here\n",
    "            processActRes(df)\n",
    "            print (df.shape)\n",
    "\n",
    "            #calling generate comparison function here\n",
    "            generatecompResult(df)\n",
    "            print (df.shape)\n",
    "            \n",
    "            #generate summary stats\n",
    "            summaryStats_df = generateSummary(df)\n",
    "\n",
    "            time = datetime.datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "            \n",
    "            reload(sys)  \n",
    "            sys.setdefaultencoding('utf-8')\n",
    "            with pd.ExcelWriter ('C:\\\\Users\\\\A6LBGZZ\\\\Bots\\\\./FinalOutput_{}.xlsx'.format(time)) as writer:\n",
    "                summaryStats_df.to_excel(writer, sheet_name = 'Summary', engine='xlsxwriter', encoding='utf-8', index=False)\n",
    "                df.to_excel(writer, sheet_name = 'Data', engine='xlsxwriter', encoding='utf-8', index=False)\n",
    "                writer.save()\n",
    "            #df.to_csv('C:\\\\Users\\\\A6LBGZZ\\\\Desktop\\\\./FinalOutput_{}.csv'.format(time), encoding='utf-8')\n",
    "            #df.to_excel('./FinalOutput_{}.xlsx'.format(time), encoding='utf8')\n",
    "            tkMessageBox.showinfo(\"Results\", \"File saved\")\n",
    "\n",
    "            file.close()\n",
    "            print \"I got %d bytes from this file.\" % len(data)\n",
    "            \n",
    "            print(file)\n",
    "            \n",
    "            #from GeneratingSummary import hello\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        if e ==\"'ascii' codec can't decode byte 0xe2 in position 163: ordinal not in range(128)\":\n",
    "            tkMessageBox.showinfo(\"Error\", \"Cannot write to xls\")\n",
    "\n",
    "menu = Menu(root)\n",
    "new_item = Menu(menu)\n",
    "\n",
    "filemenu = Menu(menu, tearoff=0)\n",
    "filemenu.add_command(label=\"Open\", command=hello)\n",
    "filemenu.add_command(label=\"Save\", command=hello)\n",
    "filemenu.add_separator()\n",
    "filemenu.add_command(label=\"Exit\", command=root.destroy)\n",
    "menu.add_cascade(label=\"File\", menu=filemenu)\n",
    "\n",
    "brwsLbl=Label(root)\n",
    "brwsLbl.grid(row=3, column=2)\n",
    "\n",
    "#prcsBtn=Button(root, text=\"BROWSE & PROCESS\", command=generatefile)\n",
    "#prcsBtn.grid(row=5, column=5)\n",
    "\n",
    "prcsBtn=Button(root, text=\"BROWSE & PROCESS\", command=generatefile)\n",
    "prcsBtn.place(bordermode = OUTSIDE,height=80, width=150)\n",
    "prcsBtn.place(relx=.5, rely=.2, anchor=\"c\") \n",
    "\n",
    "prcsBtn=Button(root, text=\"CLOSE\", command=close_window)\n",
    "prcsBtn.place(bordermode = INSIDE,height=80, width=150)\n",
    "prcsBtn.place(relx=.5, rely=0.6, anchor=\"c\") \n",
    "\n",
    "#exitBtn = Button(root, text = \"EXIT\", command = close_window)\n",
    "#exitBtn.grid(row=8, column=8)\n",
    "\n",
    "#table = tktable.Table(root, rows=10, cols=4)\n",
    "#table.pack(side=\"top\", fill=\"both\", expand=True)\n",
    "\n",
    "root.config(menu=menu)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('harish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
